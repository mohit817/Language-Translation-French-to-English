{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd758fe-27b3-4b5d-a685-465bee391a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,LSTM,Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81be684-181e-4d4a-a0aa-791e08a0b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_s = 64 # Batch size for training\n",
    "epochs = 100 # Number of epochs to train for.\n",
    "latent_dimension =  256 # Latent dimensionality of the encoding space\n",
    "number_samples = 10000 # Number of samples to train on\n",
    "# Path to the data txt file on disk\n",
    "data_path = r\"C:\\Users\\mohit\\Desktop\\data science\\Language Translation French to English\\fra.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727ea075-1624-4ab2-944b-9273212fea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path,encoding = 'utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[:min(number_samples,len(lines) - 1)]:\n",
    "    input_text,target_text,_ = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a14e6da-2cb6-40d7-9791-63502281c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 70\n",
      "Number of unique target tokens: 91\n",
      "Max sequence length for inputs: 14\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:',len(input_texts))\n",
    "print('Number of unique input tokens:',num_encoder_tokens)\n",
    "print('Number of unique target tokens:',num_decoder_tokens)\n",
    "print('Max sequence length for inputs:',max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:',max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc8d765-9953-40c2-91a0-d765c131d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char,i) for i,char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char,i) for i,char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f629419d-d7ba-4080-8919-a59d547a3b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '$': 3,\n",
       " '%': 4,\n",
       " '&': 5,\n",
       " \"'\": 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '5': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " '?': 19,\n",
       " 'A': 20,\n",
       " 'B': 21,\n",
       " 'C': 22,\n",
       " 'D': 23,\n",
       " 'E': 24,\n",
       " 'F': 25,\n",
       " 'G': 26,\n",
       " 'H': 27,\n",
       " 'I': 28,\n",
       " 'J': 29,\n",
       " 'K': 30,\n",
       " 'L': 31,\n",
       " 'M': 32,\n",
       " 'N': 33,\n",
       " 'O': 34,\n",
       " 'P': 35,\n",
       " 'Q': 36,\n",
       " 'R': 37,\n",
       " 'S': 38,\n",
       " 'T': 39,\n",
       " 'U': 40,\n",
       " 'V': 41,\n",
       " 'W': 42,\n",
       " 'Y': 43,\n",
       " 'a': 44,\n",
       " 'b': 45,\n",
       " 'c': 46,\n",
       " 'd': 47,\n",
       " 'e': 48,\n",
       " 'f': 49,\n",
       " 'g': 50,\n",
       " 'h': 51,\n",
       " 'i': 52,\n",
       " 'j': 53,\n",
       " 'k': 54,\n",
       " 'l': 55,\n",
       " 'm': 56,\n",
       " 'n': 57,\n",
       " 'o': 58,\n",
       " 'p': 59,\n",
       " 'q': 60,\n",
       " 'r': 61,\n",
       " 's': 62,\n",
       " 't': 63,\n",
       " 'u': 64,\n",
       " 'v': 65,\n",
       " 'w': 66,\n",
       " 'x': 67,\n",
       " 'y': 68,\n",
       " 'z': 69}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e1e11f-8e96-4c6a-8e43-966d9deddd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts),max_encoder_seq_length,num_encoder_tokens),\n",
    "    dtype = 'float32'\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts),max_decoder_seq_length,num_decoder_tokens),\n",
    "    dtype = 'float32'\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts),max_decoder_seq_length,num_decoder_tokens),\n",
    "    dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dd695f-32ba-4aeb-8e95-28ab6d5ef72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915473e5-b9f7-4fed-97a5-66a0a9a5cc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72db18fb-d4db-48c4-b09d-e4e86cdcfb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5471ac8b-9c98-431a-b87f-8de30dd2c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]] = 1.\n",
    "    encoder_input_data[i,t+1:,input_token_index[' ']] = 1.\n",
    "    for t,char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestamp\n",
    "        decoder_input_data[i,t,target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestamp\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[t,t-1,target_token_index[char]] = 1.\n",
    "    decoder_input_data[i,t+1:,target_token_index[char]] = 1.\n",
    "    decoder_target_data[i,t:,target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec94e76e-09d4-44c2-99cd-9af1832c0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape = (None,num_encoder_tokens))\n",
    "encoder = LSTM(latent_dimension, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard 'encoder_outputs' and only keep the states.\n",
    "encoder_states = [state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f20c946-6261-45ed-95b3-57a168f81209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using 'encoder_states' as initial state\n",
    "decoder_inputs = Input(shape = (None,num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences.\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dimension, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens,activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bdd39ce-53c6-4ef2-85f8-dbd2d1ac8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# 'encoder_input_data' & 'decoder_input_data' into 'decoder_target_data'\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9d2b04f-6dc0-4ba4-8a2a-e0e2b31911d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "125/125 [==============================] - 21s 131ms/step - loss: 0.1522 - accuracy: 0.6963 - val_loss: 0.0314 - val_accuracy: 0.6637\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.0818 - accuracy: 0.7019 - val_loss: 0.0416 - val_accuracy: 0.6637\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.0837 - accuracy: 0.7019 - val_loss: 0.0339 - val_accuracy: 0.6637\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.0822 - accuracy: 0.7019 - val_loss: 0.0389 - val_accuracy: 0.6637\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.0790 - accuracy: 0.7019 - val_loss: 0.0769 - val_accuracy: 0.6637\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.0711 - accuracy: 0.7019 - val_loss: 0.0462 - val_accuracy: 0.6637\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0633 - accuracy: 0.7019 - val_loss: 0.0326 - val_accuracy: 0.6637\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 20s 161ms/step - loss: 0.0577 - accuracy: 0.7016 - val_loss: 0.0236 - val_accuracy: 0.6633\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.0612 - accuracy: 0.7010 - val_loss: 0.0293 - val_accuracy: 0.6631\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.0609 - accuracy: 0.7011 - val_loss: 0.0283 - val_accuracy: 0.6635\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.0535 - accuracy: 0.7014 - val_loss: 0.0225 - val_accuracy: 0.6636\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.0544 - accuracy: 0.7016 - val_loss: 0.0169 - val_accuracy: 0.6635\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 21s 166ms/step - loss: 0.0507 - accuracy: 0.7015 - val_loss: 0.0257 - val_accuracy: 0.6634\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0515 - accuracy: 0.7016 - val_loss: 0.0310 - val_accuracy: 0.6635\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 0.0499 - accuracy: 0.7018 - val_loss: 0.0291 - val_accuracy: 0.6637\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0474 - accuracy: 0.7019 - val_loss: 0.0245 - val_accuracy: 0.6637\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 21s 166ms/step - loss: 0.0452 - accuracy: 0.7018 - val_loss: 0.0203 - val_accuracy: 0.6637\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 21s 165ms/step - loss: 0.0504 - accuracy: 0.7019 - val_loss: 0.0284 - val_accuracy: 0.6637\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.0506 - accuracy: 0.7019 - val_loss: 0.0310 - val_accuracy: 0.6637\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 0.0517 - accuracy: 0.7019 - val_loss: 0.0216 - val_accuracy: 0.6637\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 0.0471 - accuracy: 0.7019 - val_loss: 0.0209 - val_accuracy: 0.6637\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.0500 - accuracy: 0.7019 - val_loss: 0.0231 - val_accuracy: 0.6637\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 0.0452 - accuracy: 0.7019 - val_loss: 0.0149 - val_accuracy: 0.6637\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0491 - accuracy: 0.7019 - val_loss: 0.0286 - val_accuracy: 0.6637\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 22s 174ms/step - loss: 0.0459 - accuracy: 0.7019 - val_loss: 0.0195 - val_accuracy: 0.6637\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 21s 171ms/step - loss: 0.0425 - accuracy: 0.7019 - val_loss: 0.0205 - val_accuracy: 0.6637\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 23s 182ms/step - loss: 0.0424 - accuracy: 0.7019 - val_loss: 0.0164 - val_accuracy: 0.6637\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.0412 - accuracy: 0.7019 - val_loss: 0.0179 - val_accuracy: 0.6637\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.0420 - accuracy: 0.7019 - val_loss: 0.0183 - val_accuracy: 0.6637\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 24s 190ms/step - loss: 0.0443 - accuracy: 0.7019 - val_loss: 0.0255 - val_accuracy: 0.6637\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.0449 - accuracy: 0.7019 - val_loss: 0.0180 - val_accuracy: 0.6637\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.0436 - accuracy: 0.7019 - val_loss: 0.0201 - val_accuracy: 0.6637\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.0408 - accuracy: 0.7019 - val_loss: 0.0184 - val_accuracy: 0.6637\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.0466 - accuracy: 0.7019 - val_loss: 0.0219 - val_accuracy: 0.6637\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.0462 - accuracy: 0.7019 - val_loss: 0.0190 - val_accuracy: 0.6637\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.0441 - accuracy: 0.7019 - val_loss: 0.0233 - val_accuracy: 0.6637\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 22s 174ms/step - loss: 0.0501 - accuracy: 0.7019 - val_loss: 0.0190 - val_accuracy: 0.6637\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 21s 165ms/step - loss: 0.0440 - accuracy: 0.7019 - val_loss: 0.0226 - val_accuracy: 0.6637\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 26s 212ms/step - loss: 0.0506 - accuracy: 0.7019 - val_loss: 0.0228 - val_accuracy: 0.6637\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.0499 - accuracy: 0.7019 - val_loss: 0.0241 - val_accuracy: 0.6637\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.0451 - accuracy: 0.7019 - val_loss: 0.0212 - val_accuracy: 0.6637\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.0477 - accuracy: 0.7019 - val_loss: 0.0222 - val_accuracy: 0.6637\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.0527 - accuracy: 0.7019 - val_loss: 0.0333 - val_accuracy: 0.6637\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 20s 161ms/step - loss: 0.0529 - accuracy: 0.7019 - val_loss: 0.0254 - val_accuracy: 0.6637\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0519 - accuracy: 0.7019 - val_loss: 0.0242 - val_accuracy: 0.6637\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 22s 179ms/step - loss: 0.0509 - accuracy: 0.7019 - val_loss: 0.0217 - val_accuracy: 0.6637\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 0.0543 - accuracy: 0.7019 - val_loss: 0.0239 - val_accuracy: 0.6637\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 21s 171ms/step - loss: 0.0460 - accuracy: 0.7019 - val_loss: 0.0187 - val_accuracy: 0.6637\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0506 - accuracy: 0.7019 - val_loss: 0.0231 - val_accuracy: 0.6637\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 21s 165ms/step - loss: 0.0491 - accuracy: 0.7019 - val_loss: 0.0170 - val_accuracy: 0.6637\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0447 - accuracy: 0.7019 - val_loss: 0.0354 - val_accuracy: 0.6637\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 21s 171ms/step - loss: 0.0560 - accuracy: 0.7019 - val_loss: 0.0200 - val_accuracy: 0.6637\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 21s 165ms/step - loss: 0.0492 - accuracy: 0.7019 - val_loss: 0.0225 - val_accuracy: 0.6637\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 21s 169ms/step - loss: 0.0574 - accuracy: 0.7019 - val_loss: 0.0271 - val_accuracy: 0.6637\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0510 - accuracy: 0.7019 - val_loss: 0.0169 - val_accuracy: 0.6637\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 20s 159ms/step - loss: 0.0620 - accuracy: 0.7019 - val_loss: 0.0193 - val_accuracy: 0.6637\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.0430 - accuracy: 0.7019 - val_loss: 0.0185 - val_accuracy: 0.6637\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 22s 174ms/step - loss: 0.0405 - accuracy: 0.7019 - val_loss: 0.0164 - val_accuracy: 0.6637\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 23s 182ms/step - loss: 0.0423 - accuracy: 0.7019 - val_loss: 0.0171 - val_accuracy: 0.6637\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 0.0488 - accuracy: 0.7019 - val_loss: 0.0675 - val_accuracy: 0.6637\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.0599 - accuracy: 0.7019 - val_loss: 0.0433 - val_accuracy: 0.6637\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0614 - accuracy: 0.7019 - val_loss: 0.0175 - val_accuracy: 0.6637\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 20s 161ms/step - loss: 0.0413 - accuracy: 0.7019 - val_loss: 0.0165 - val_accuracy: 0.6637\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.0507 - accuracy: 0.7019 - val_loss: 0.0142 - val_accuracy: 0.6637\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 21s 169ms/step - loss: 0.0423 - accuracy: 0.7019 - val_loss: 0.0199 - val_accuracy: 0.6636\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 22s 177ms/step - loss: 0.0427 - accuracy: 0.7019 - val_loss: 0.0135 - val_accuracy: 0.6637\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 23s 183ms/step - loss: 0.0480 - accuracy: 0.7019 - val_loss: 0.0348 - val_accuracy: 0.6637\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.0526 - accuracy: 0.7018 - val_loss: 0.0154 - val_accuracy: 0.6637\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 22s 177ms/step - loss: 0.0435 - accuracy: 0.7018 - val_loss: 0.0190 - val_accuracy: 0.6637\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 22s 175ms/step - loss: 0.0483 - accuracy: 0.7012 - val_loss: 0.0170 - val_accuracy: 0.6637\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 22s 179ms/step - loss: 0.0471 - accuracy: 0.7018 - val_loss: 0.0164 - val_accuracy: 0.6636\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0410 - accuracy: 0.7018 - val_loss: 0.0195 - val_accuracy: 0.6637\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 21s 169ms/step - loss: 0.0449 - accuracy: 0.7018 - val_loss: 0.0172 - val_accuracy: 0.6637\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.0588 - accuracy: 0.7018 - val_loss: 0.0338 - val_accuracy: 0.6632\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.0635 - accuracy: 0.6999 - val_loss: 0.0273 - val_accuracy: 0.6632\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0524 - accuracy: 0.6997 - val_loss: 0.0212 - val_accuracy: 0.6634\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 21s 169ms/step - loss: 0.0527 - accuracy: 0.7002 - val_loss: 0.0164 - val_accuracy: 0.6634\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0444 - accuracy: 0.6997 - val_loss: 0.0237 - val_accuracy: 0.6627\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 21s 165ms/step - loss: 0.0522 - accuracy: 0.6997 - val_loss: 0.0187 - val_accuracy: 0.6637\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.0467 - accuracy: 0.6997 - val_loss: 0.0222 - val_accuracy: 0.6637\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.0484 - accuracy: 0.6999 - val_loss: 0.0201 - val_accuracy: 0.6637\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 20s 161ms/step - loss: 0.0444 - accuracy: 0.6997 - val_loss: 0.0255 - val_accuracy: 0.6626\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0462 - accuracy: 0.6997 - val_loss: 0.0101 - val_accuracy: 0.6637\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 21s 168ms/step - loss: 0.0526 - accuracy: 0.6996 - val_loss: 0.0158 - val_accuracy: 0.6637\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 21s 171ms/step - loss: 0.0432 - accuracy: 0.7014 - val_loss: 0.0219 - val_accuracy: 0.6634\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.0521 - accuracy: 0.7000 - val_loss: 0.0173 - val_accuracy: 0.6634\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.0482 - accuracy: 0.6996 - val_loss: 0.0236 - val_accuracy: 0.6634\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 21s 169ms/step - loss: 0.0461 - accuracy: 0.6999 - val_loss: 0.0209 - val_accuracy: 0.6625\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 21s 169ms/step - loss: 0.0429 - accuracy: 0.6999 - val_loss: 0.0121 - val_accuracy: 0.6637\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.0471 - accuracy: 0.6998 - val_loss: 0.0113 - val_accuracy: 0.6637\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 20s 162ms/step - loss: 0.0371 - accuracy: 0.7006 - val_loss: 0.0129 - val_accuracy: 0.6637\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0383 - accuracy: 0.6998 - val_loss: 0.0182 - val_accuracy: 0.6623\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 21s 166ms/step - loss: 0.0385 - accuracy: 0.7000 - val_loss: 0.0172 - val_accuracy: 0.6637\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 20s 162ms/step - loss: 0.0400 - accuracy: 0.7010 - val_loss: 0.0087 - val_accuracy: 0.6637\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0455 - accuracy: 0.7001 - val_loss: 0.0189 - val_accuracy: 0.6637\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 20s 161ms/step - loss: 0.0557 - accuracy: 0.6998 - val_loss: 0.0178 - val_accuracy: 0.6634\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 20s 162ms/step - loss: 0.0394 - accuracy: 0.7007 - val_loss: 0.0213 - val_accuracy: 0.6628\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.0460 - accuracy: 0.7001 - val_loss: 0.0150 - val_accuracy: 0.6634\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 21s 169ms/step - loss: 0.0515 - accuracy: 0.6987 - val_loss: 0.0149 - val_accuracy: 0.6634\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 22s 174ms/step - loss: 0.0551 - accuracy: 0.6982 - val_loss: 0.0243 - val_accuracy: 0.6624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23668cff3d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'rmsprop',metrics = ['accuracy'])\n",
    "\n",
    "model.fit([encoder_input_data,decoder_input_data], decoder_target_data,\n",
    "         batch_size = batch_s,\n",
    "         epochs = epochs,\n",
    "         validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "576ed972-8c63-4feb-ba95-caff93cb5f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save('seq2seq.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca46a15-4c58-4ab5-bfcb-08b8b25c3939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
